{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EXAM Review.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8FkgWXOuG_Y"
      },
      "source": [
        "- Q1. Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr3h2uCOsjBi"
      },
      "source": [
        "class Parent:\n",
        "  def __init__(self, p1, p2):\n",
        "    self.p1 = p1\n",
        "    self.p2 = p2\n",
        "\n",
        "  p3 = \"Dummy\" # Class 전역 변수는 self 사용하지 않음 \n",
        "\n",
        "class Child_1(Parent):\n",
        "  def __init__(self, b1, **kwargs):\n",
        "    self.b1 = b1\n",
        "\n",
        "class Child_2(Parent):\n",
        "  def __init__(self, c1, **kwargs)   :\n",
        "    super().__init__(**kwargs)\n",
        "    self.c1 = c1\n",
        "\n",
        "A = Parent(10, 20)\n",
        "B = Child_1(100, p1 = 30, p2 = 40)\n",
        "C = Child_2(100, p1 = 50, p2 = 60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Aal1J2ktoIx"
      },
      "source": [
        "print( A.p1 , A.p2)\n",
        "#print( B.b1, B.p1, B.p2)\n",
        "print( C.c1, C.p1, C.p2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW3zp1FZtjOv"
      },
      "source": [
        "- Q2. numpy & pandas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1mTnaqouR98"
      },
      "source": [
        "import numpy as np\n",
        "data = np.array([[1,2,3],[4,5,6]])\n",
        "\n",
        "# reverse in numpy\n",
        "z = np.arange(10)\n",
        "reverse = z[::-1]\n",
        "# 행바꾸기 \n",
        "row = data[[1,0]]\n",
        "# 열도 바꾸기 \n",
        "col = data[[1,0]][:,[2,1,0]] \n",
        "\n",
        "print(reverse)\n",
        "print(row)\n",
        "print(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLmDgSa3zBdY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dic = {'도시': ['서울', '부산', '대전', '대구', '광주'],\n",
        "        'year': [2017, 2017, 2018, 2018, 2018],\n",
        "        'temp': [18, 20, 19, 21, 20]}\n",
        "\n",
        "data = pd.DataFrame(dic) \n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90-BKGQG1GfU"
      },
      "source": [
        "# 특정 행 얻는 법 - Index(pandas에서의 row) or 우리가 아는 index로  \n",
        "data.index = ['a','b','c','d','e'] \n",
        "\n",
        "# method 1 행 이름으로 ! \n",
        "print( data.loc['a'] )  \n",
        "print()\n",
        "print( data.loc['a' : 'c']) # 'c' 포함\n",
        "print()\n",
        "\n",
        "# method 2 행 번호로 !\n",
        "print( data.iloc[0] )\n",
        "print()\n",
        "print( data.iloc[0:2] ) # 2 포함 XX !\n",
        "\n",
        "# 특정 열 얻는 법 \n",
        "print()\n",
        "print( data['year']) # numpy index처럼 바로 고냥 갖다박으면 된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63fCPj-YUUi"
      },
      "source": [
        "# 열 추가 \n",
        "data['New'] = ['1','2','3','4','5']\n",
        "\n",
        "# 열 삭제\n",
        "data = data.drop(['New'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT-Rsgwg3KHR"
      },
      "source": [
        "# in place\n",
        "data.set_index(['도시'], inplace=True) \n",
        "data # inplace=False면 안바뀌고 고대로 ~"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzYpaPiE1T-J"
      },
      "source": [
        "df = pd.DataFrame(np.arange(12).reshape(4, 3), \n",
        "                  columns=['A', 'B', 'C'], index=['a', 'b', 'c', 'd'])\n",
        "\n",
        "# numpy와 달리 pandas의 default는 axis = 0이다. 전체 XX !!\n",
        "print(df.max())\n",
        "print()\n",
        "print(df.max())\n",
        "print()\n",
        "print(df.max(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QVlvNZV5Atc"
      },
      "source": [
        "# dataframe 정렬 \n",
        "df = pd.DataFrame(np.arange(8).reshape((2, 4)), index=['three', 'one'],\n",
        "                  columns=['d', 'a', 'b', 'c'])\n",
        "\n",
        "# 행 header 정렬\n",
        "df.sort_index() \n",
        "\n",
        "# 열 header 정렬\n",
        "df.sort_index(axis = 1)  # df.sort_columne 같은 건 없다 개 페이크 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9wWRWJt5jiT"
      },
      "source": [
        "# 열 value 정렬\n",
        "frame = pd.DataFrame({'b': [4,7,3,2], 'a': [4,9,2,5], 'c': [5,3,7,9]}) \n",
        "\n",
        "frame.sort_values(by = 'a') # a 열의 값을 기준으로 정렬 나머지를 따라오기\n",
        "frame.sort_values(by = 'b') # b 열의 값을 기준으로 정렬 나머지를 따라오기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD--f_Uc5oGL"
      },
      "source": [
        "obj = pd.Series([100, 33, 99, 33])\n",
        "\n",
        "# 순위 매기기 --- 동점자는 평균값 줌\n",
        "obj.rank(ascending=False) \n",
        "\n",
        "# 동일한 값이 존재 할 경우 먼저 나타나는 것에게 높은 순위를 줄 수 있다\n",
        "obj.rank(method='first', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enQ5NN6J6AUj"
      },
      "source": [
        "df = pd.DataFrame({'b': [4,7,3,2], 'a': [4,9,2,5], 'c': [5,3,7,9]})\n",
        "\n",
        "# ---------- df에도 rank 수행할 수 있는데, axis = 0이 열기준이다 조금 이상하지만 참고하자.\n",
        "df.rank() # 열 기준으로 순위 매기기\n",
        "df.rank(axis=1) # 행 기준으로 순위 매기기 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc0V0PvM6N_o"
      },
      "source": [
        "# Nan Value 처리\n",
        "from numpy import nan as NA\n",
        "df = pd.DataFrame([[NA, 6.5, 3.], [NA, NA, NA],\n",
        "                  [NA, NA, NA], [NA, 6.5, 3.]])\n",
        "\n",
        "# 한 항목이라도 NA가 있으면 해당 행을 삭제한다\n",
        "cleaned = df.dropna()\n",
        "# 한 항목이라도 NA가 있으면 해당 열을 삭제한다\n",
        "clean2 = df.dropna(axis=1)\n",
        "\n",
        "# 행의 모든 항목이 NA일때 해당 행을 삭제한다\n",
        "df.dropna(how='all')\n",
        "# 열의 모든 항목이 NA일때 해당 열을 삭제한다\n",
        "clean2 = df.dropna(axis=1, how='all')\n",
        "\n",
        "# 해당 행에 2개 이상 Nan이 있으면 삭제 \n",
        "df.dropna(thresh=2) # Keep only the rows with at least 2 non-NA values.\n",
        "\n",
        "# 컬럼별로 다른 값을 채울 수 있다. 사전을 사용한다\n",
        "df.fillna({1: 0.5, 2: -1}) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G68pkT_B8o0R"
      },
      "source": [
        "- Q3. HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxmFkydt8qyF"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_text = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "  <h1> reading web page with python </h1>\n",
        "     <p> page analysis </p>\n",
        "     <p> page alignment </p>\n",
        "     <td>some text</td><td></td><td><p>more text</p></td><td>even <p>more text</p></td>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "# <td> : table \n",
        "\n",
        "soup = BeautifulSoup(html_text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv6U_9Fp9VF-"
      },
      "source": [
        "# 기본 method \n",
        "print(soup.h1) # <h1> 에 대한 string 가져오기\n",
        "print(soup.h1.text) # <h1> 에 대한 string을 각주 빼고 get\n",
        "print(soup.h1.text.strip()) # 공백 문자 제거 \n",
        "\n",
        "print(soup.p)\n",
        "print(soup.p.next_sibling.next_sibling.text.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaXBp6hp9ngx"
      },
      "source": [
        "# Tag로 가져오기 --- 더 많이 사용 \n",
        "html_text2 = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "  <h1 id=\"title\"> reading web page with python </h1>\n",
        "     <p id=\"body\"> page analysis </p>\n",
        "     <p> page alignment </p>\n",
        "     <td>some text</td><td></td><td><p>more text</p></td><td>even <p>more text</p></td>\n",
        "     <ul>\n",
        "         <li><a href = \"http://www.naver.com\"> naver</a></li>\n",
        "         <li><a href = \"http://www.daum.net\"> daum</a></li>\n",
        "     </ul>\n",
        "  <div id=\"xxx\">\n",
        "    <h1> Wiki-books store </h1>\n",
        "    <ul class=\"item\">\n",
        "      <li> introduction to game design </li>\n",
        "      <li> introduction to python </li>\n",
        "      <li> introduction to web design </li>\n",
        "    </ul>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_text2, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD7wf6Bp9pUs"
      },
      "source": [
        "soup.find(id = 'title')\n",
        "soup.find(id = 'title').text.strip()\n",
        "\n",
        "soup.find_all('p') # <p> 붙어 있는 놈 다 가져와라 --- list 로 가져옴 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3or8OeV-GJT"
      },
      "source": [
        "# <li><a href = \"http://www.naver.com\"> naver</a></li>\n",
        "soup.find('a').attrs # 해당 태그에 붙어있는 속성 ---  {'href': 'http://www.naver.com'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkxhnxNq-VYE"
      },
      "source": [
        "for aa in soup.find_all('a'): # 모든 <a>를 가져오고, 하나씩 iteration \n",
        "    href = aa.attrs['href'] # dict 형태 # <a>의 속성\n",
        "    text = aa.string # <a>의 내용 \n",
        "    print(text, \"-->\", href)\n",
        "\n",
        "'''\n",
        "naver --> http://www.naver.com\n",
        "daum --> http://www.daum.net\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMUzgNUGIvMX"
      },
      "source": [
        "# find with Regular Expression \n",
        "import re\n",
        "soup.find_all(re.compile(\"^p\"))  # <p> 다 가져오라\n",
        "soup.find_all(re.compile(\"div\")) # div 다 가져와라\n",
        "soup.find_all(href = re.compile(\"^http://\")) # href가 http 인 놈 다 가져와라 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9O8g4xj_Ps4"
      },
      "source": [
        "# CSS method --- select 함수 사용\n",
        "\n",
        "# find_all == select\n",
        "soup.find('h1') # 얘는 하나만 찾는다. 다 찾으려면 find_all 사용 \n",
        "soup.select('h1') # 이것도 tag로 찾는다. but 다 찾는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDiCS2c_nhx"
      },
      "source": [
        "#  하위에 있는 내용들 싹다 가져온다\n",
        "soup.select('#xxx')  # by id \n",
        "soup.select('.item') # by class name\n",
        "soup.select('div .item')  # (tag=div, class=item)  --- class는 . 붙여서 구별 \n",
        "soup.select(\"div li\")   # hierarchy div 안에 있는 li 모두 return ( div >> li )\n",
        "\n",
        "soup.select_one(\"#xxx > ul > li\")  # hierarchy! id xxx 안에 태크 ul 안에 태그 li를 하나만 return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyXr1aPtJtXJ"
      },
      "source": [
        "text = '''<p class=\"body strikeout\"> hello </p>\n",
        "\n",
        "          <p class=\"body strikeout\"> hello2 </p>\n",
        "          <p class=\"body\"> hello3 </p>\n",
        "'''\n",
        "\n",
        "css_soup = BeautifulSoup(text, 'html.parser')\n",
        "css_soup.find_all(\"p\", class_=\"strikeout\")  # p 타입의 class strikeout class 모두 다 가져오기 \n",
        "css_soup.find_all(\"p\", class_=\"body\")\n",
        "# class에 여러 가지 값이 있을 수 있다. class_ = body로 불러도 되고 class_ = strikeout 으로 불러도 된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpNspCYAL7sw"
      },
      "source": [
        "# Example\n",
        "\n",
        "import requests # internet에서 file을 가져오는 라이브러리 \n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://kr.indeed.com/jobs?q=data+science&l=%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C'\n",
        "link = requests.get(url)\n",
        "soup = BeautifulSoup(link.text, 'html.parser')\n",
        "\n",
        "job_elems = soup.select('.resultContent') # 해당하는 이름의 class 싹다 list로 가져오기 --- select 자너 \n",
        "\n",
        "for i in job_elems:\n",
        "\n",
        "    # find는 하나만 가져온다 \n",
        "    title = i.find('h2') # h2 태그 찾기 \n",
        "    company = i.find('span', class_='companyName') # span 타입의 class companyName 태그 찾기\n",
        "    location = i.find('div', class_='companyLocation') # div 타입의 class companyLocation 태그 찾기\n",
        "    \n",
        "    if None in (title, company, location):\n",
        "        continue\n",
        "        \n",
        "    print(title.text.strip())\n",
        "    print()\n",
        "    print(company.text.strip())\n",
        "    print(location.text.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIaX1Va1MQ3t"
      },
      "source": [
        "- Q4. BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVfD-SDVOybL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# CounterVectorizor : Corpus에서 나오는 단어를 모두 모아서 Colume으로 만듬 ( 행 : document , 열 : 단어 )\n",
        "# 각 Document에서 Columne에 해당하는 단어가 몇 번 나오는 지 Count\n",
        "\n",
        "corpus = [\n",
        "    'This is the first document',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?'\n",
        "]\n",
        "\n",
        "vect = CountVectorizer()\n",
        "# vect = CountVectorizer(min_df=10)  최소한 10번은 등장해야 단어로 보겠다.\n",
        "X = vect.fit_transform(corpus) # 단어가 몇 개 나오는지 Count \n",
        "print(X.toarray())\n",
        "print(vect.get_feature_names())\n",
        "'''\n",
        "[[0 1 1 1 0 0 1 0 1]\n",
        " [0 2 0 1 0 1 1 0 1]\n",
        " [1 0 0 1 1 0 1 1 1]\n",
        " [0 1 1 1 0 0 1 0 1]]\n",
        "\n",
        "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLBDBhPnWhOz"
      },
      "source": [
        "# TFIDF : log ( document 개수 / 해당 단어를 가진 document 개수 )   ( 독 / 단 )\n",
        "vect = TfidfVectorizer() \n",
        "X = vect.fit_transform(corpus)\n",
        "print(X.toarray().round(1))\n",
        "print(vect.get_feature_names()) # 알파벳 순서로 정렬되므로, 단어들 간의 순서와 서로 간의 의미가 무시된다.\n",
        "'''\n",
        "[[0.  0.5 0.6 0.4 0.  0.  0.4 0.  0.4]\n",
        " [0.  0.7 0.  0.3 0.  0.5 0.3 0.  0.3]\n",
        " [0.5 0.  0.  0.3 0.5 0.  0.3 0.5 0.3]\n",
        " [0.  0.5 0.6 0.4 0.  0.  0.4 0.  0.4]]\n",
        "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63cJLUS9WWU-"
      },
      "source": [
        "# stop words 흔한 단어, 필요없는 단어  ngram_range : 1개 2개 1개 2개 ... \n",
        "vect = TfidfVectorizer(ngram_range=[1,2], stop_words='english') \n",
        "X = vect.fit_transform(corpus)\n",
        "print(X.toarray().round(1))\n",
        "print(vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S1gJYbzXFBy"
      },
      "source": [
        "iidx = X.toarray().sum(0).argsort()[-5:] # 가장 많이 나온거 5개의 index return \n",
        "#array([ 7, 12,  6, 18,  2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnNe9wW4X6ZU"
      },
      "source": [
        "- Q5. Missing Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyVHtX6IX8sw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from numpy import nan as NA\n",
        "df = pd.DataFrame([[NA, 6.5, 3.], [NA, NA, NA],\n",
        "                  [NA, NA, NA], [NA, 6.5, 3.]])\n",
        "\n",
        "df.isna().sum() # 각 열에 대해서 NA의 개수 return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2zn8GyJZ6sB"
      },
      "source": [
        "df.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLNoSnLDfPIs"
      },
      "source": [
        "- One hot Encoding\n",
        "- Ordinal Encoding\n",
        "- Label Encoding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUeXzVHeaW8D"
      },
      "source": [
        "# One-hot Encoding : Nominal data \n",
        "# Label / Ordianl Encoding : Ordinal data \n",
        "# Label Encoding : to Target Value\n",
        "# One-hot / Ordinal Encoding : to feature Values\n",
        "\n",
        "X, y = df.values[:, :-1], df.values[:,-1]\n",
        "oe = OrdinalEncoder()\n",
        "X_enc = oe.fit_transform(X)\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "oe.categories_, le.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMY9PWmBfOa6"
      },
      "source": [
        "- Standard Scaling\n",
        "\n",
        "      z = (x - mean) / std\n",
        "\n",
        "- Min - Max Scaling\n",
        "\n",
        "      z = x - min / max - min \n",
        "\n",
        "- Robust Scaling\n",
        "\n",
        "      z = x - median / IQR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEjJXy-zfVST"
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'x1': np.random.normal(0, 2, 10000),\n",
        "    'x2': np.random.normal(5, 3, 10000),\n",
        "    'x3': np.random.normal(-5, 5, 10000)\n",
        "})\n",
        "df.head()\n",
        "df.plot.kde()  # kernel density estimate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9jyKyJifdE3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "ss = StandardScaler()\n",
        "data_tf = ss.fit_transform(df)     # returns an array\n",
        "df = pd.DataFrame(data_tf, columns=['x1','x2','x3'])\n",
        "df.plot.kde()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCDOMnnifhrs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "mm = MinMaxScaler()\n",
        "data_tf = mm.fit_transform(df)\n",
        "df1 = pd.DataFrame(data_tf,columns=['x1','x2','x3'])\n",
        "\n",
        "sc = StandardScaler()\n",
        "data_tf = sc.fit_transform(df)\n",
        "df2 = pd.DataFrame(data_tf,columns=['x1','x2','x3'])\n",
        "\n",
        "rb = RobustScaler()\n",
        "data_tf = rb.fit_transform(df)\n",
        "df3 = pd.DataFrame(data_tf,columns=['x1','x2','x3'])\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16,6))\n",
        "df1.plot.kde(ax=axes[0])\n",
        "df2.plot.kde(ax=axes[1])\n",
        "df3.plot.kde(ax=axes[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjtb3mztfohj"
      },
      "source": [
        "- Q6. GD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpw3sCzPkBTg"
      },
      "source": [
        "w1 = np.random.randn()\n",
        "w2 = np.random.randn()\n",
        "b  = np.random.randn() \n",
        "\n",
        "def sigmoid_activation(z):\n",
        "    return 1.0 / (1 + np.exp(-z))\n",
        "\n",
        "lossHistory = []\n",
        "epochs = 300\n",
        "alpha = 0.01\n",
        "\n",
        "for epoch in np.arange(epochs):\n",
        "    preds = sigmoid_activation(w1*x1 + w2*x2 + b)       # prediction\n",
        "\n",
        "    loss = -( ( y*np.log(preds) + (1-y)*np.log(1-preds) ) ).mean()  # loss = cross entropy\n",
        "    lossHistory.append(loss)\n",
        "    \n",
        "    dloss_dz = preds - y\n",
        "    w1_deriv = dloss_dz * x1        # d(loss)/dw1 = d(loss)/dz * dz/dw1\n",
        "    w2_deriv = dloss_dz * x2\n",
        "    b_deriv = dloss_dz * 1\n",
        "    \n",
        "    w1 = w1 - (alpha * w1_deriv).mean()\n",
        "    w2 = w2 - (alpha * w2_deriv).mean()\n",
        "    b  = b  - (alpha * b_deriv).mean()\n",
        "\n",
        "print(w1, w2, b)\n",
        "accuracy = ((sigmoid_activation(w1*x1 + w2*x2 + b) > 0.5) == y).sum()/N\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
